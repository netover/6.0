# ============================================================
# .env.example — Resync v6.2.0 environment variables
#
# Copy to .env and fill in real values before first deployment:
#   cp .env.example .env && chmod 600 .env
#
# NEVER commit .env to version control.
# ============================================================

# ── Application ──────────────────────────────────────────────
APP_ENVIRONMENT=production
APP_LOG_LEVEL=INFO
APP_LOG_FORMAT=json
HOST=0.0.0.0
PORT=8000

# ── Security ─────────────────────────────────────────────────
# Generate with: python -c "import secrets; print(secrets.token_hex(32))"
APP_SECRET_KEY=CHANGE_ME_generate_with_secrets_token_hex_32
APP_ADMIN_PASSWORD=CHANGE_ME_min_8_chars

# ── Database (PostgreSQL) ────────────────────────────────────
# Format: postgresql+asyncpg://user:password@host:port/database
APP_DATABASE_URL=postgresql+asyncpg://resync:CHANGE_ME@localhost:5432/resync
POSTGRES_DB=resync
POSTGRES_USER=resync
POSTGRES_PASSWORD=CHANGE_ME

# ── Redis ────────────────────────────────────────────────────
# Format: redis://:password@host:port/db
APP_REDIS_URL=redis://:CHANGE_ME@localhost:6379/0
REDIS_PASSWORD=CHANGE_ME

# ── LLM / AI ─────────────────────────────────────────────────
# OpenAI-compatible endpoint (NVIDIA NIM, Azure OpenAI, vLLM, etc.)
APP_LLM_API_KEY=CHANGE_ME
APP_LLM_ENDPOINT=https://integrate.api.nvidia.com/v1
APP_LLM_MODEL=meta/llama-3.1-70b-instruct

# ── CORS (comma-separated allowed origins) ───────────────────
APP_CORS_ALLOWED_ORIGINS=https://yourdomain.com

# ── Rate Limiting ─────────────────────────────────────────────
RATE_LIMIT_ENABLED=true
RATE_LIMIT_AUTH_REQUESTS=10
RATE_LIMIT_AUTH_WINDOW_SECONDS=60
RATE_LIMIT_API_REQUESTS=120
RATE_LIMIT_API_WINDOW_SECONDS=60

# ── Gunicorn ──────────────────────────────────────────────────
WEB_CONCURRENCY=4
TIMEOUT=60
GRACEFUL_TIMEOUT=30
# SECURITY: Set to your nginx/LB IP. Default is localhost-only.
FORWARDED_ALLOW_IPS=127.0.0.1
# Set TRUSTED_HOSTS to your domain(s) in production
TRUSTED_HOSTS=yourdomain.com,www.yourdomain.com

# ── Prometheus (multiprocess — required with multiple Gunicorn workers) ─────
# Must be a writable directory. All workers write metrics here.
# Without this, metrics aggregation across workers will be incorrect.
PROMETHEUS_MULTIPROC_DIR=/tmp/prometheus_multiproc

# ── Observability ─────────────────────────────────────────────
# Sentry DSN (optional — leave empty to disable)
SENTRY_DSN=

# OpenTelemetry OTLP endpoint (optional)
OTEL_EXPORTER_OTLP_ENDPOINT=

# ── Teams Webhook (optional) ──────────────────────────────────
TEAMS_WEBHOOK_URL=
TEAMS_WEBHOOK_ENABLED=false

# ── TWS Integration ───────────────────────────────────────────
TWS_HOST=localhost
TWS_PORT=31116
TWS_USERNAME=CHANGE_ME
TWS_PASSWORD=CHANGE_ME
