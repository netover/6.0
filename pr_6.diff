diff --git a/resync/api/monitoring_dashboard.py b/resync/api/monitoring_dashboard.py
index e797067..8457e13 100644
--- a/resync/api/monitoring_dashboard.py
+++ b/resync/api/monitoring_dashboard.py
@@ -1,40 +1,88 @@
-# monitoring_dashboard.py — API endpoint para dashboard interno de monitoramento
-# Substitui necessidade de Prometheus/Grafana com solução leve e integrada
+# monitoring_dashboard.py — API endpoint para dashboard interno de monitoramento (Redis Version)
+# Substitui necessidade de Prometheus/Grafana com solução distribuída e sincronizada.
 #
 # Características:
-#   - Rolling window de 2 horas em memória (~1.4 MB)
-#   - Atualização a cada 5 segundos
-#   - Zero dependências externas
-#   - Integrado com métricas existentes do Resync
-
+#   - Persistência Global em Redis (History List e Latest Hash)
+#   - Broadcast sincronizado via Redis Pub/Sub (Sincronização entre workers)
+#   - Liderança Distribuída: Apenas um worker coleta métricas por vez (Resolução de Duplicação)
+#   - Alta Performance: Serialização otimizada com orjson

 import asyncio
 import logging
 import time
-from collections import deque
-from dataclasses import dataclass, field
+from contextlib import suppress
+from dataclasses import dataclass, asdict
 from datetime import datetime, timezone
 from typing import Any

-from fastapi import APIRouter, WebSocket, WebSocketDisconnect
+from fastapi import APIRouter, WebSocket, WebSocketDisconnect, status
 from fastapi.responses import JSONResponse

+from resync.core.redis_init import get_redis_client
+from resync.api.security import decode_token
+
 logger = logging.getLogger(__name__)

-# Configurações do rolling buffer
-HISTORY_WINDOW_SECONDS = 2 * 60 * 60  # 2 horas
-SAMPLE_INTERVAL_SECONDS = 5  # Amostragem a cada 5s
-MAX_SAMPLES = HISTORY_WINDOW_SECONDS // SAMPLE_INTERVAL_SECONDS  # 1440 amostras
+# ── Configurações e Keys ───────────────────────────────────────────────────
+
+SAMPLE_INTERVAL_SECONDS = 5
+MAX_SAMPLES = (2 * 60 * 60) // SAMPLE_INTERVAL_SECONDS  # 2 horas
+MAX_WS_CONNECTIONS = 50
+WS_SEND_TIMEOUT = 1.0  # Tempo máximo para envio em um WebSocket lento
+
+# Redis Keys
+REDIS_KEY_HISTORY = "resync:monitoring:history"
+REDIS_KEY_ALERTS = "resync:monitoring:alerts"
+REDIS_KEY_LATEST = "resync:monitoring:latest"
+REDIS_KEY_START_TIME = "resync:monitoring:start_time"
+REDIS_CH_BROADCAST = "resync:monitoring:broadcast"
+REDIS_LOCK_COLLECTOR = "resync:monitoring:collector:lock"
+
+
+# ── Helpers de Serialização ──────────────────────────────────────────────────
+
+try:
+    import orjson
+    def json_dumps(data: Any) -> str:
+        return orjson.dumps(data).decode()
+    def json_loads(data: str | bytes) -> Any:
+        return orjson.loads(data)
+except ImportError:
+    import json
+    def json_dumps(data: Any) -> str:
+        return json.dumps(data)
+    def json_loads(data: str | bytes) -> Any:
+        return json.loads(data)
+
+
+def _safe_float(val: Any, default: float = 0.0) -> float:
+    try: return float(val) if val is not None else default
+    except (TypeError, ValueError): return default
+
+def _safe_int(val: Any, default: int = 0) -> int:
+    try: return int(val) if val is not None else default
+    except (TypeError, ValueError): return default
+
+
+def _safe_json_loads(data: str | bytes, context: str) -> dict | list | None:
+    """Parse JSON com tratamento de erro robusto."""
+    if not data: return None
+    try:
+        return json_loads(data)
+    except Exception as e:
+        logger.error("JSON corrompido (%s): %s", context, e)
+        return None
+

+# ── Data Models ──────────────────────────────────────────────────────────────

-@dataclass
+@dataclass(slots=True)
 class MetricSample:
     """Uma amostra de métricas em um ponto no tempo."""
-
     timestamp: float
     datetime_str: str

-    # API Metrics
+    # API
     requests_total: int = 0
     requests_per_sec: float = 0.0
     error_count: int = 0
@@ -43,506 +91,401 @@ class MetricSample:
     response_time_p95: float = 0.0
     response_time_avg: float = 0.0

-    # Cache Metrics
+    # Cache
     cache_hits: int = 0
     cache_misses: int = 0
     cache_hit_ratio: float = 0.0
     cache_size: int = 0
     cache_evictions: int = 0

-    # Agent Metrics
+    # Agent
     agents_active: int = 0
     agents_created: int = 0
     agents_failed: int = 0

-    # LLM Metrics
+    # LLM
     llm_requests: int = 0
     llm_tokens_used: int = 0
     llm_errors: int = 0

-    # TWS Metrics
+    # TWS
     tws_connected: bool = False
     tws_latency_ms: float = 0.0
     tws_errors: int = 0
     tws_requests_success: int = 0
     tws_requests_failed: int = 0

-    # System Metrics
+    # System
     system_uptime: float = 0.0
     system_availability: float = 100.0
     async_operations_active: int = 0
     correlation_ids_active: int = 0

+    collection_error: str | None = None

-@dataclass
-class DashboardMetricsStore:
-    """Store para métricas do dashboard com rolling window."""
-
-    samples: deque[MetricSample] = field(default_factory=lambda: deque(maxlen=MAX_SAMPLES))
-    start_time: float = field(default_factory=time.time)
-    last_sample_time: float = 0.0
-    _lock: asyncio.Lock = field(default_factory=asyncio.Lock)

-    # Contadores acumulados para calcular deltas
-    _prev_requests: int = 0
-    _prev_cache_hits: int = 0
-    _prev_cache_misses: int = 0
-    _prev_agents_created: int = 0
-    _prev_llm_requests: int = 0
+# ── Dashboard Metrics Store ──────────────────────────────────────────────────

-    # Alertas ativos
-    alerts: list[dict[str, Any]] = field(default_factory=list)
+class DashboardMetricsStore:
+    """Store de métricas persistido no Redis para consistência global."""
+
+    def __init__(self):
+        self._prev_requests = 0
+        self._last_sample_mono = 0.0
+        self._local_lock = asyncio.Lock()
+
+    async def compute_rate_and_add_sample(self, requests_total: int, now_mono: float, sample_builder: Any) -> None:
+        """Calcula RPS localmente e persiste no Redis."""
+        async with self._local_lock:
+            time_delta = now_mono - self._last_sample_mono if self._last_sample_mono > 0 else SAMPLE_INTERVAL_SECONDS
+            req_delta = requests_total - self._prev_requests if self._prev_requests > 0 else 0
+            rps = req_delta / time_delta if time_delta > 0 else 0.0
+
+            self._prev_requests = requests_total
+            self._last_sample_mono = now_mono
+
+            sample = sample_builder(rps)
+            await self.add_sample(sample)
+
+    async def add_error_sample(self, error: Exception) -> None:
+        """Persiste amostra indicando falha na coleta."""
+        now_wall = time.time()
+        dt_str = datetime.now(timezone.utc).strftime("%H:%M:%S")
+        error_msg = str(error)[:197] + "..." if len(str(error)) > 200 else str(error)
+        global_uptime = await self.get_global_uptime()
+
+        sample = MetricSample(
+            timestamp=now_wall, datetime_str=dt_str, collection_error=error_msg,
+            system_uptime=global_uptime, system_availability=0.0,
+            tws_connected=True  # Evita alerta falso
+        )
+        await self.add_sample(sample)

     async def add_sample(self, sample: MetricSample) -> None:
-        """Adiciona uma nova amostra ao histórico."""
-        async with self._lock:
-            self.samples.append(sample)
-            self.last_sample_time = sample.timestamp
+        """Persiste amostra no Redis e gera alertas."""
+        redis = get_redis_client()
+        data = json_dumps(asdict(sample))

-            # Verificar alertas
-            self._check_alerts(sample)
+        pipe = redis.pipeline()
+        pipe.lpush(REDIS_KEY_HISTORY, data)
+        pipe.ltrim(REDIS_KEY_HISTORY, 0, MAX_SAMPLES - 1)
+        pipe.set(REDIS_KEY_LATEST, data)
+        await pipe.execute()

-    def _check_alerts(self, sample: MetricSample) -> None:
-        """Verifica condições de alerta."""
-        new_alerts = []
+        await self._check_alerts_redis(sample)

-        # Alerta: Error rate > 5%
+    async def _check_alerts_redis(self, sample: MetricSample) -> None:
+        """Verifica alertas e persiste no Redis."""
+        new_alerts = []
         if sample.error_rate > 5.0:
-            new_alerts.append(
-                {
-                    "type": "error_rate",
-                    "severity": "warning" if sample.error_rate < 10 else "critical",
-                    "message": "Error rate elevado: {sample.error_rate:.1f}%",
-                    "timestamp": sample.datetime_str,
-                }
-            )
-
-        # Alerta: Cache hit ratio < 80%
-        if sample.cache_hit_ratio < 80.0 and (sample.cache_hits + sample.cache_misses) > 100:
-            new_alerts.append(
-                {
-                    "type": "cache_ratio",
-                    "severity": "warning",
-                    "message": "Cache hit ratio baixo: {sample.cache_hit_ratio:.1f}%",
-                    "timestamp": sample.datetime_str,
-                }
-            )
-
-        # Alerta: Response time > 500ms
-        if sample.response_time_p95 > 500:
-            new_alerts.append(
-                {
-                    "type": "latency",
-                    "severity": "warning" if sample.response_time_p95 < 1000 else "critical",
-                    "message": "Latência P95 elevada: {sample.response_time_p95:.0f}ms",
-                    "timestamp": sample.datetime_str,
-                }
-            )
-
-        # Alerta: TWS desconectado
-        if not sample.tws_connected:
-            new_alerts.append(
-                {
-                    "type": "tws_connection",
-                    "severity": "critical",
-                    "message": "TWS desconectado",
-                    "timestamp": sample.datetime_str,
-                }
-            )
-
-        # Manter últimos 20 alertas
-        self.alerts = (new_alerts + self.alerts)[:20]
+            new_alerts.append({
+                "type": "error_rate", "severity": "critical" if sample.error_rate >= 10 else "warning",
+                "message": f"Error rate: {sample.error_rate:.1f}%", "timestamp": sample.datetime_str
+            })
+        if sample.collection_error is None and not sample.tws_connected:
+            new_alerts.append({
+                "type": "tws", "severity": "critical",
+                "message": "TWS desconectado", "timestamp": sample.datetime_str
+            })
+
+        if new_alerts:
+            redis = get_redis_client()
+            pipe = redis.pipeline()
+            for alert in new_alerts:
+                pipe.lpush(REDIS_KEY_ALERTS, json_dumps(alert))
+            pipe.ltrim(REDIS_KEY_ALERTS, 0, 19) # Manter últimos 20
+            await pipe.execute()
+
+    async def get_global_uptime(self) -> float:
+        redis = get_redis_client()
+        try:
+            now = time.time()
+            was_set = await redis.set(REDIS_KEY_START_TIME, str(now), nx=True)
+            raw = await redis.get(REDIS_KEY_START_TIME)
+            return now - float(raw or now)
+        except Exception: return 0.0

     async def get_current_metrics(self) -> dict[str, Any]:
-        """Retorna métricas atuais para o dashboard."""
-        async with self._lock:
-            if not self.samples:
-                return self._empty_metrics()
-
-            current = self.samples[-1]
-
-            # Calcular tendências (comparando com 5 minutos atrás)
-            trend_sample = None
-            if len(self.samples) > 60:  # 60 amostras = 5 minutos
-                trend_sample = self.samples[-61]
-
-            return {
-                "status": "ok" if current.error_rate < 5 else "degraded",
-                "uptime": self._format_uptime(current.system_uptime),
-                "uptime_seconds": current.system_uptime,
-                "version": "5.1.0",
-                "last_update": current.datetime_str,
-                "timestamp": current.timestamp,
-                "api": {
-                    "requests_per_sec": round(current.requests_per_sec, 1),
-                    "requests_total": current.requests_total,
-                    "error_rate": round(current.error_rate, 2),
-                    "error_count": current.error_count,
-                    "response_time_p50": round(current.response_time_p50, 1),
-                    "response_time_p95": round(current.response_time_p95, 1),
-                    "response_time_avg": round(current.response_time_avg, 1),
-                    "trend": self._calc_trend(
-                        current.requests_per_sec,
-                        trend_sample.requests_per_sec if trend_sample else 0,
-                    ),
-                },
-                "cache": {
-                    "hit_ratio": round(current.cache_hit_ratio, 1),
-                    "hits": current.cache_hits,
-                    "misses": current.cache_misses,
-                    "size": current.cache_size,
-                    "evictions": current.cache_evictions,
-                    "trend": self._calc_trend(
-                        current.cache_hit_ratio, trend_sample.cache_hit_ratio if trend_sample else 0
-                    ),
-                },
-                "agents": {
-                    "active": current.agents_active,
-                    "created_total": current.agents_created,
-                    "failed_total": current.agents_failed,
-                    "trend": self._calc_trend(
-                        current.agents_active, trend_sample.agents_active if trend_sample else 0
-                    ),
-                },
-                "llm": {
-                    "requests": current.llm_requests,
-                    "tokens_used": current.llm_tokens_used,
-                    "errors": current.llm_errors,
-                },
-                "tws": {
-                    "connected": current.tws_connected,
-                    "latency_ms": round(current.tws_latency_ms, 1),
-                    "requests_success": current.tws_requests_success,
-                    "requests_failed": current.tws_requests_failed,
-                    "status": "online" if current.tws_connected else "offline",
-                },
-                "system": {
-                    "availability": round(current.system_availability, 2),
-                    "async_operations": current.async_operations_active,
-                    "correlation_ids": current.correlation_ids_active,
-                },
-                "alerts": self.alerts[:5],  # Últimos 5 alertas
-            }
+        redis = get_redis_client()
+        try:
+            raw = await redis.get(REDIS_KEY_LATEST)
+            if not raw: return self._empty_response("initializing")
+
+            data = _safe_json_loads(raw, "latest")
+            if not data: return self._empty_response("data_error")
+
+            alerts_raw = await redis.lrange(REDIS_KEY_ALERTS, 0, 4)
+            alerts = [p for a in alerts_raw if (p := _safe_json_loads(a, "alert"))]
+
+            return self._format_metrics_dict(data, alerts)
+        except Exception as e:
+            logger.error("Erro ao obter métricas: %s", e)
+            return self._empty_response("error")

     async def get_history(self, minutes: int = 120) -> dict[str, Any]:
-        """Retorna histórico de métricas para gráficos."""
-        async with self._lock:
-            # Calcular quantas amostras pegar
-            samples_needed = min(len(self.samples), (minutes * 60) // SAMPLE_INTERVAL_SECONDS)
-
-            if samples_needed == 0:
-                return self._empty_history()
-
-            # Pegar últimas N amostras
-            recent_samples = list(self.samples)[-samples_needed:]
-
-            # Formatar para gráficos
+        redis = get_redis_client()
+        try:
+            needed = (minutes * 60) // SAMPLE_INTERVAL_SECONDS
+            raw_list = await redis.lrange(REDIS_KEY_HISTORY, 0, needed - 1)
+            if not raw_list: return self._empty_history()
+
+            samples = [p for r in reversed(raw_list) if (p := _safe_json_loads(r, "history"))]
+            if not samples: return self._empty_history()
+
             return {
-                "timestamps": [s.datetime_str for s in recent_samples],
+                "timestamps": [s.get("datetime_str", "") for s in samples],
                 "api": {
-                    "requests_per_sec": [round(s.requests_per_sec, 1) for s in recent_samples],
-                    "error_rate": [round(s.error_rate, 2) for s in recent_samples],
-                    "response_time_p50": [round(s.response_time_p50, 1) for s in recent_samples],
-                    "response_time_p95": [round(s.response_time_p95, 1) for s in recent_samples],
-                },
-                "cache": {
-                    "hit_ratio": [round(s.cache_hit_ratio, 1) for s in recent_samples],
-                    "operations": [s.cache_hits + s.cache_misses for s in recent_samples],
-                },
-                "agents": {
-                    "active": [s.agents_active for s in recent_samples],
-                    "created": [s.agents_created for s in recent_samples],
-                },
-                "tws": {
-                    "latency": [round(s.tws_latency_ms, 1) for s in recent_samples],
-                    "connected": [1 if s.tws_connected else 0 for s in recent_samples],
-                },
-                "sample_count": len(recent_samples),
-                "interval_seconds": SAMPLE_INTERVAL_SECONDS,
+                    "requests_per_sec": [round(s.get("requests_per_sec", 0), 1) for s in samples],
+                    "error_rate": [round(s.get("error_rate", 0), 2) for s in samples]},
+                "cache": {"hit_ratio": [round(s.get("cache_hit_ratio", 0), 1) for s in samples]},
+                "agents": {"active": [s.get("agents_active", 0) for s in samples]},
+                "sample_count": len(samples)
             }
-
-    def _empty_metrics(self) -> dict[str, Any]:
-        """Retorna estrutura vazia de métricas."""
-        return {
-            "status": "initializing",
-            "uptime": "0s",
-            "uptime_seconds": 0,
-            "version": "5.1.0",
-            "last_update": datetime.now(timezone.utc).strftime("%H:%M:%S"),
-            "timestamp": time.time(),
-            "api": {"requests_per_sec": 0, "error_rate": 0, "response_time_p95": 0, "trend": 0},
-            "cache": {"hit_ratio": 0, "hits": 0, "misses": 0, "trend": 0},
-            "agents": {"active": 0, "created_total": 0, "failed_total": 0, "trend": 0},
-            "llm": {"requests": 0, "tokens_used": 0, "errors": 0},
-            "tws": {"connected": False, "latency_ms": 0, "status": "unknown"},
-            "system": {"availability": 0, "async_operations": 0},
-            "alerts": [],
-        }
-
-    def _empty_history(self) -> dict[str, Any]:
-        """Retorna estrutura vazia de histórico."""
+        except Exception as e:
+            logger.error("Erro ao obter histórico: %s", e)
+            return self._empty_history()
+
+    def _format_metrics_dict(self, current: dict, alerts: list) -> dict:
+        err_msg = current.get("collection_error")
+        error_rate = current.get("error_rate", 0)
+        if err_msg:
+            status_val = "collection_error"
+        elif error_rate >= 10:
+            status_val = "critical"
+        elif error_rate >= 5:
+            status_val = "degraded"
+        else:
+            status_val = "ok"
+
         return {
-            "timestamps": [],
+            "status": status_val, "uptime_seconds": round(current.get("system_uptime", 0), 1),
+            "last_update": current.get("datetime_str"),
             "api": {
-                "requests_per_sec": [],
-                "error_rate": [],
-                "response_time_p50": [],
-                "response_time_p95": [],
+                "requests_per_sec": round(current.get("requests_per_sec", 0), 1),
+                "requests_total": current.get("requests_total", 0),
+                "error_rate": round(current.get("error_rate", 0), 2)
             },
-            "cache": {"hit_ratio": [], "operations": []},
-            "agents": {"active": [], "created": []},
-            "tws": {"latency": [], "connected": []},
-            "sample_count": 0,
-            "interval_seconds": SAMPLE_INTERVAL_SECONDS,
+            "system": {"availability": round(current.get("system_availability", 100), 2)},
+            "alerts": alerts, "collection_error": err_msg
         }

-    def _format_uptime(self, seconds: float) -> str:
-        """Formata uptime para exibição."""
-        if seconds < 60:
-            return f"{int(seconds)}s"
-        if seconds < 3600:
-            return f"{int(seconds // 60)}m {int(seconds % 60)}s"
-        if seconds < 86400:
-            hours = int(seconds // 3600)
-            mins = int((seconds % 3600) // 60)
-            return f"{hours}h {mins}m"
-        days = int(seconds // 86400)
-        hours = int((seconds % 86400) // 3600)
-        return f"{days}d {hours}h"
-
-    def _calc_trend(self, current: float, previous: float) -> float:
-        """Calcula tendência em porcentagem."""
-        if previous == 0:
-            return 0
-        return round(((current - previous) / previous) * 100, 1)
-
+    def _empty_response(self, status: str) -> dict:
+        return {"status": status, "api": {"requests_per_sec": 0}, "alerts": []}

-# Singleton do store
-_metrics_store: DashboardMetricsStore | None = None
-_collector_task: asyncio.Task | None = None
+    def _empty_history(self) -> dict:
+        return {"timestamps": [], "api": {"requests_per_sec": [], "error_rate": []}, "sample_count": 0}


-def get_metrics_store() -> DashboardMetricsStore:
-    """Obtém o store singleton."""
-    global _metrics_store
-    if _metrics_store is None:
-        _metrics_store = DashboardMetricsStore()
-    return _metrics_store
+# ── WebSocket Manager ────────────────────────────────────────────────────────

+class WebSocketManager:
+    """Gerencia conexões WebSocket locais e sincroniza via Redis Pub/Sub."""

-async def collect_metrics_sample() -> MetricSample:
-    """Coleta uma amostra das métricas atuais do sistema."""
-    from resync.core.metrics import get_runtime_metrics
+    def __init__(self):
+        self._clients: set[WebSocket] = set()
+        self._lock = asyncio.Lock()
+        self._sync_task: asyncio.Task | None = None
+        self._stop_event = asyncio.Event()

-    try:
-        metrics = get_runtime_metrics()
-        snapshot = metrics.get_snapshot()
-
-        now = time.time()
-        store = get_metrics_store()
-
-        # Calcular requests/sec baseado no delta
-        requests_total = (
-            snapshot.get("agent", {}).get("initializations", 0)
-            + snapshot.get("tws", {}).get("success", 0)
-            if "tws" in snapshot
-            else snapshot.get("audit", {}).get("records_created", 0)
-        )
+    async def start_sync(self):
+        if self._stop_event.is_set():
+            return
+        if self._sync_task is None or self._sync_task.done():
+            self._sync_task = asyncio.create_task(self._pubsub_listener())

-        # Estimar requests/sec (simplificado)
-        time_delta = (
-            now - store.last_sample_time if store.last_sample_time > 0 else SAMPLE_INTERVAL_SECONDS
-        )
-        requests_delta = requests_total - store._prev_requests
-        requests_per_sec = requests_delta / time_delta if time_delta > 0 else 0
-        store._prev_requests = requests_total
-
-        # Cache metrics
-        cache = snapshot.get("cache", {})
-        cache_hits = cache.get("hits", 0)
-        cache_misses = cache.get("misses", 0)
-        cache_total = cache_hits + cache_misses
-        cache_hit_ratio = (cache_hits / cache_total * 100) if cache_total > 0 else 100
-
-        # SLO metrics
-        slo = snapshot.get("slo", {})
+    async def stop(self) -> None:
+        self._stop_event.set()
+        if self._sync_task and not self._sync_task.done():
+            self._sync_task.cancel()
+            with suppress(asyncio.CancelledError):
+                await self._sync_task
+        self._sync_task = None

-        return MetricSample(
-            timestamp=now,
-            datetime_str=datetime.now(timezone.utc).strftime("%H:%M:%S"),
-            # API
-            requests_total=requests_total,
-            requests_per_sec=max(0, requests_per_sec),
-            error_count=snapshot.get("agent", {}).get("creation_failures", 0),
-            error_rate=slo.get("api_error_rate", 0) * 100,
-            response_time_p50=slo.get("api_response_time_p50", 0) * 1000,  # ms
-            response_time_p95=slo.get("api_response_time_p95", 0) * 1000,  # ms
-            response_time_avg=(
-                slo.get("api_response_time_p50", 0) + slo.get("api_response_time_p95", 0)
-            )
-            / 2
-            * 1000,
-            # Cache
-            cache_hits=cache_hits,
-            cache_misses=cache_misses,
-            cache_hit_ratio=cache_hit_ratio,
-            cache_size=int(cache.get("size", 0)),
-            cache_evictions=cache.get("evictions", 0),
-            # Agents
-            agents_active=snapshot.get("agent", {}).get("active_count", 0),
-            agents_created=snapshot.get("agent", {}).get("initializations", 0),
-            agents_failed=snapshot.get("agent", {}).get("creation_failures", 0),
-            # LLM metrics from snapshot
-            llm_requests=snapshot.get("llm", {}).get("requests", 0),
-            llm_tokens_used=snapshot.get("llm", {}).get("tokens_used", 0),
-            llm_errors=snapshot.get("llm", {}).get("errors", 0),
-            # TWS
-            tws_connected=slo.get("tws_connection_success_rate", 0) > 0.5,
-            tws_latency_ms=slo.get("api_response_time_p50", 0) * 1000,
-            tws_errors=0,
-            tws_requests_success=0,
-            tws_requests_failed=0,
-            # System
-            system_uptime=now - store.start_time,
-            system_availability=slo.get("availability", 1.0) * 100,
-            async_operations_active=snapshot.get("system", {}).get("async_operations_active", 0),
-            correlation_ids_active=snapshot.get("system", {}).get("correlation_ids_active", 0),
-        )
+    async def connect(self, websocket: WebSocket) -> bool:
+        async with self._lock:
+            if len(self._clients) >= MAX_WS_CONNECTIONS: return False
+            self._clients.add(websocket)
+            return True

-    except Exception as e:
-        logger.error("Erro ao coletar métricas: %s", e)
-        return MetricSample(timestamp=time.time(), datetime_str=datetime.now(timezone.utc).strftime("%H:%M:%S"))
+    async def disconnect(self, websocket: WebSocket):
+        async with self._lock:
+            self._clients.discard(websocket)
+
+    async def _pubsub_listener(self):
+        while not self._stop_event.is_set():
+            pubsub = None
+            try:
+                redis = get_redis_client()
+                pubsub = redis.pubsub()
+                await pubsub.subscribe(REDIS_CH_BROADCAST)
+                logger.info("WebSocketManager sincronizado com Redis Pub/Sub")
+                async for message in pubsub.listen():
+                    if self._stop_event.is_set():
+                        break
+                    if message["type"] == "message":
+                        data = message["data"]
+                        if isinstance(data, bytes): data = data.decode()
+                        await self._local_broadcast(data)
+            except asyncio.CancelledError:
+                logger.info("WebSocketManager Pub/Sub listener cancelado")
+                break
+            except Exception:
+                logger.exception("Pub/Sub desconectado; tentando reconectar em 5s")
+                if not self._stop_event.is_set():
+                    await asyncio.sleep(5)
+            finally:
+                if pubsub is not None:
+                    with suppress(Exception):
+                        await pubsub.unsubscribe(REDIS_CH_BROADCAST)
+                    close_fn = getattr(pubsub, "close", None)
+                    if close_fn is not None:
+                        with suppress(Exception):
+                            maybe_awaitable = close_fn()
+                            if asyncio.iscoroutine(maybe_awaitable):
+                                await maybe_awaitable
+
+    async def broadcast(self, message_str: str) -> None:
+        await self._local_broadcast(message_str)
+
+    async def _local_broadcast(self, message_str: str):
+        async with self._lock:
+            clients = list(self._clients)
+
+        async def _safe_send(ws: WebSocket):
+            try:
+                await asyncio.wait_for(ws.send_text(message_str), timeout=WS_SEND_TIMEOUT)
+            except Exception:
+                logger.exception("Falha ao enviar mensagem WebSocket; desconectando cliente")
+                await self.disconnect(ws)

+        if clients:
+            tasks = [asyncio.create_task(_safe_send(c)) for c in clients]
+            await asyncio.gather(*tasks, return_exceptions=True)

-async def metrics_collector_loop():
-    """Loop de coleta de métricas em background."""
-    store = get_metrics_store()

-    while True:
-        try:
-            sample = await collect_metrics_sample()
-            await store.add_sample(sample)
-        except Exception as e:
-            logger.error("Erro no collector loop: %s", e)
-
-        await asyncio.sleep(SAMPLE_INTERVAL_SECONDS)
+# ── WebSocket Authentication ─────────────────────────────────────────────────

+async def _verify_ws_admin(websocket: WebSocket) -> str | None:
+    """Valida autenticação admin para WebSocket."""
+    try:
+        token = websocket.query_params.get("access_token")
+        if not token:
+            auth_header = websocket.headers.get("authorization", "")
+            if auth_header.startswith("Bearer "):
+                token = auth_header[7:]
+
+        if not token: return None
+
+        payload = decode_token(token)
+        username = payload.get("sub")
+
+        # Verificar se é admin (suporta roles ou scopes)
+        roles_claim = payload.get("roles")
+        if roles_claim is None:
+            legacy_role = payload.get("role")
+            roles = [legacy_role] if legacy_role else []
+        elif isinstance(roles_claim, list):
+            roles = roles_claim
+        else:
+            roles = [roles_claim]
+        if "admin" not in roles: return None
+
+        return username
+    except Exception: return None
+
+
+# ── Singletons ───────────────────────────────────────────────────────────────
+
+_metrics_store = DashboardMetricsStore()
+ws_manager = WebSocketManager()
+
+
+# ── Collector Logic ──────────────────────────────────────────────────────────
+
+async def collect_metrics_sample() -> None:
+    """Apenas um worker coleta por vez (Liderança via Redis Lock)."""
+    redis = get_redis_client()
+    if not await redis.set(REDIS_LOCK_COLLECTOR, "leader", ex=8, nx=True):
+        return
+
+    from resync.core.metrics import runtime_metrics
+    try:
+        snapshot = runtime_metrics.get_snapshot()
+        now_mono = time.monotonic()
+        now_wall = time.time()
+        dt_str = datetime.now(timezone.utc).strftime("%H:%M:%S")

-def start_metrics_collector():
-    """Inicia o coletor de métricas em background."""
-    global _collector_task
+        agent = snapshot.get("agent", {})
+        slo = snapshot.get("slo", {})
+        req_total = _safe_int(agent.get("initializations"))
+        uptime = await _metrics_store.get_global_uptime()
+
+        def build_sample(rps: float) -> MetricSample:
+            return MetricSample(
+                timestamp=now_wall, datetime_str=dt_str,
+                requests_total=req_total, requests_per_sec=rps,
+                error_rate=_safe_float(slo.get("api_error_rate")) * 100,
+                tws_connected=_safe_float(slo.get("tws_connection_success_rate")) > 0.5,
+                system_uptime=uptime, system_availability=_safe_float(slo.get("availability"), 1.0) * 100
+            )

-    if _collector_task is None or _collector_task.done():
-        try:
-            loop = asyncio.get_event_loop()
-            _collector_task = loop.create_task(metrics_collector_loop())
-            logger.info("Dashboard metrics collector iniciado")
-        except RuntimeError:
-            # Não há event loop rodando ainda
-            logger.warning("Event loop não disponível, collector será iniciado depois")
+        await _metrics_store.compute_rate_and_add_sample(req_total, now_mono, build_sample)
+
+        current = await _metrics_store.get_current_metrics()
+        subscribers = await redis.publish(REDIS_CH_BROADCAST, json_dumps(current))
+        if subscribers == 0: logger.debug("Nenhum subscriber no canal de broadcast")

+    except Exception as e:
+        logger.error("Erro na coleta: %s", e)
+        await _metrics_store.add_error_sample(e)
+        current = await _metrics_store.get_current_metrics()
+        await redis.publish(REDIS_CH_BROADCAST, json_dumps(current))

-def stop_metrics_collector():
-    """Para o coletor de métricas."""
-    global _collector_task

-    if _collector_task and not _collector_task.done():
-        _collector_task.cancel()
-        logger.info("Dashboard metrics collector parado")
+async def metrics_collector_loop() -> None:
+    try:
+        redis = get_redis_client()
+        await redis.ping()
+    except Exception as e:
+        logger.error("Redis não disponível, encerrando collector: %s", e); return
+
+    await ws_manager.start_sync()
+    while True:
+        try: await collect_metrics_sample()
+        except asyncio.CancelledError: break
+        except Exception:
+            logger.exception("Erro no collector loop ao executar collect_metrics_sample")
+        await asyncio.sleep(SAMPLE_INTERVAL_SECONDS)


-# =====================================
-# FastAPI Router
-# =====================================
+# ── FastAPI Router ────────────────────────────────────────────────────────────

 router = APIRouter(prefix="/api/monitoring", tags=["monitoring"])

-
-# Nota: @router.on_event("startup") foi removido (deprecado no FastAPI 0.111+)
-# Lógica de inicialização do metrics collector movida para app_factory.py lifespan manager
-# O collector é iniciado automaticamente no startup da aplicação
-
-
 @router.get("/current")
-async def get_current_metrics():
-    """
-    Retorna métricas atuais do sistema.
-
-    Substitui necessidade de Prometheus + Grafana com solução integrada.
-    Consumo: ~50MB RAM vs ~1.2GB do stack externo.
-    """
-    store = get_metrics_store()
-    return JSONResponse(content=await store.get_current_metrics())
-
+async def get_current():
+    return await _metrics_store.get_current_metrics()

 @router.get("/history")
-async def get_metrics_history(minutes: int = 120):
-    """
-    Retorna histórico de métricas para gráficos.
-
-    Args:
-        minutes: Minutos de histórico (máx 120 = 2 horas)
-
-    Returns:
-        Dados formatados para Chart.js
-    """
-    minutes = min(max(1, minutes), 120)  # Limitar entre 1-120 minutos
-    store = get_metrics_store()
-    return JSONResponse(content=await store.get_history(minutes))
-
-
-@router.get("/alerts")
-async def get_active_alerts():
-    """Retorna alertas ativos do sistema."""
-    store = get_metrics_store()
-    async with store._lock:
-        return JSONResponse(content={"alerts": store.alerts, "count": len(store.alerts)})
-
-
-@router.get("/health")
-async def monitoring_health():
-    """Health check do sistema de monitoramento."""
-    store = get_metrics_store()
-    return JSONResponse(
-        content={
-            "status": "healthy",
-            "samples_collected": len(store.samples),
-            "max_samples": MAX_SAMPLES,
-            "history_window": f"{HISTORY_WINDOW_SECONDS // 3600}h",
-            "sample_interval": f"{SAMPLE_INTERVAL_SECONDS}s",
-            "memory_estimate_mb": round(len(store.samples) * 0.001, 2),  # ~1KB por amostra
-        }
-    )
-
-
-# WebSocket para atualizações em tempo real
-connected_clients: list[WebSocket] = []
-
+async def get_history(minutes: int = 120):
+    return await _metrics_store.get_history(min(max(1, minutes), 120))

 @router.websocket("/ws")
 async def websocket_metrics(websocket: WebSocket):
-    """
-    WebSocket para métricas em tempo real.
-
-    Envia atualizações a cada 5 segundos automaticamente.
-    """
+    """WebSocket para métricas em tempo real com autenticação."""
+    username = await _verify_ws_admin(websocket)
+    if not username:
+        await websocket.close(code=status.WS_1008_POLICY_VIOLATION)
+        return
+
     await websocket.accept()
-    connected_clients.append(websocket)
-
+    if not await ws_manager.connect(websocket):
+        await websocket.close(code=status.WS_1013_TRY_AGAIN_LATER); return
+
     try:
-        store = get_metrics_store()
-
+        initial = await _metrics_store.get_current_metrics()
+        await websocket.send_json(initial)
         while True:
-            # Enviar métricas atuais
-            metrics = await store.get_current_metrics()
-            await websocket.send_json(metrics)
-
-            # Aguardar próximo intervalo
-            await asyncio.sleep(SAMPLE_INTERVAL_SECONDS)
-
-    except WebSocketDisconnect:
-        connected_clients.remove(websocket)
-    except Exception as e:
-        logger.error("WebSocket error: %s", e)
-        if websocket in connected_clients:
-            connected_clients.remove(websocket)
+            await websocket.receive_text()
+    except (WebSocketDisconnect, asyncio.CancelledError): pass
+    finally: await ws_manager.disconnect(websocket)
diff --git a/tests/test_workflows_nodes_verbose_history.py b/tests/test_workflows_nodes_verbose_history.py
new file mode 100644
index 0000000..6843fcc
--- /dev/null
+++ b/tests/test_workflows_nodes_verbose_history.py
@@ -0,0 +1,126 @@
+from datetime import datetime, timezone
+from types import SimpleNamespace
+from unittest.mock import AsyncMock
+
+import pytest
+
+from workflows.nodes_verbose import (
+    fetch_job_execution_history,
+    fetch_workstation_metrics_history,
+)
+
+
+@pytest.mark.asyncio
+async def test_fetch_job_execution_history_uses_named_mappings_and_fallbacks(monkeypatch):
+    monkeypatch.setenv("ENABLE_PREDICTIVE_WORKFLOWS", "true")
+
+    now = datetime(2026, 1, 1, 12, 0, tzinfo=timezone.utc)
+    rows = [
+        {
+            "timestamp": now,
+            "job_name": "JOB_A",
+            "workstation": None,
+            "status": None,
+            "return_code": None,
+            "runtime_seconds": None,
+            "scheduled_time": now,
+            "actual_start_time": now,
+            "completed_time": now,
+        }
+    ]
+
+    result = SimpleNamespace(mappings=lambda: SimpleNamespace(fetchall=lambda: rows))
+    db = AsyncMock()
+    db.execute = AsyncMock(return_value=result)
+
+    history = await fetch_job_execution_history(db=db)
+
+    assert len(history) == 1
+    assert history[0]["timestamp"] == now.isoformat()
+    assert history[0]["job_name"] == "JOB_A"
+    assert history[0]["workstation"] == "UNKNOWN"
+    assert history[0]["status"] == "UNKNOWN"
+    assert history[0]["return_code"] == 0
+    assert history[0]["runtime_seconds"] == 0
+    assert history[0]["scheduled_time"] == now.isoformat()
+    assert history[0]["actual_start_time"] == now.isoformat()
+    assert history[0]["completed_time"] == now.isoformat()
+
+
+@pytest.mark.asyncio
+async def test_fetch_workstation_metrics_history_uses_named_mappings(monkeypatch):
+    monkeypatch.setenv("ENABLE_PREDICTIVE_WORKFLOWS", "true")
+
+    now = datetime(2026, 1, 2, 13, 0, tzinfo=timezone.utc)
+    rows = [
+        {
+            "timestamp": now,
+            "workstation": "WS01",
+            "cpu_percent": 10.5,
+            "memory_percent": 45.0,
+            "disk_percent": 70.2,
+            "load_avg_1min": 0.8,
+            "cpu_count": 8,
+            "total_memory_gb": 32,
+            "total_disk_gb": 512,
+        }
+    ]
+
+    result = SimpleNamespace(mappings=lambda: SimpleNamespace(fetchall=lambda: rows))
+    db = AsyncMock()
+    db.execute = AsyncMock(return_value=result)
+
+    history = await fetch_workstation_metrics_history(db=db)
+
+    assert len(history) == 1
+    assert history[0] == {
+        "timestamp": now.isoformat(),
+        "workstation": "WS01",
+        "cpu_percent": 10.5,
+        "memory_percent": 45.0,
+        "disk_percent": 70.2,
+        "load_avg_1min": 0.8,
+        "cpu_count": 8,
+        "total_memory_gb": 32,
+        "total_disk_gb": 512,
+    }
+
+
+@pytest.mark.asyncio
+async def test_fetch_workstation_metrics_history_handles_none_fields(monkeypatch):
+    monkeypatch.setenv("ENABLE_PREDICTIVE_WORKFLOWS", "true")
+
+    now = datetime(2026, 1, 3, 14, 0, tzinfo=timezone.utc)
+    rows = [
+        {
+            "timestamp": now,
+            "workstation": "WS02",
+            "cpu_percent": None,
+            "memory_percent": None,
+            "disk_percent": None,
+            "load_avg_1min": None,
+            "cpu_count": None,
+            "total_memory_gb": None,
+            "total_disk_gb": None,
+        }
+    ]
+
+    result = SimpleNamespace(mappings=lambda: SimpleNamespace(fetchall=lambda: rows))
+    db = AsyncMock()
+    db.execute = AsyncMock(return_value=result)
+
+    history = await fetch_workstation_metrics_history(db=db)
+
+    assert len(history) == 1
+    assert history[0] == {
+        "timestamp": now.isoformat(),
+        "workstation": "WS02",
+        "cpu_percent": 0.0,
+        "memory_percent": 0.0,
+        "disk_percent": 0.0,
+        "load_avg_1min": 0.0,
+        "cpu_count": 0,
+        "total_memory_gb": 0.0,
+        "total_disk_gb": 0.0,
+    }
+
diff --git a/tests/verify_dashboard_redis.py b/tests/verify_dashboard_redis.py
new file mode 100644
index 0000000..ab633d3
--- /dev/null
+++ b/tests/verify_dashboard_redis.py
@@ -0,0 +1,74 @@
+import asyncio
+import logging
+from unittest.mock import MagicMock, AsyncMock, patch, ANY
+import time
+
+# ✅ Importar do caminho correto
+from resync.api.monitoring_dashboard import (
+    DashboardMetricsStore,
+    MetricSample,
+    ws_manager,
+    collect_metrics_sample,
+    REDIS_CH_BROADCAST,
+)
+
+async def verify_dashboard_redis():
+    logger = logging.getLogger(__name__)
+    logger.setLevel(logging.ERROR)
+
+    # 1. Mock Redis Client
+    mock_redis = MagicMock()
+    mock_redis.set = AsyncMock(return_value=True)
+    mock_redis.get = AsyncMock(return_value='{"status": "ok", "api": {"requests_per_sec": 0}}')
+    mock_redis.lrange = AsyncMock(return_value=[])
+    mock_redis.publish = AsyncMock(return_value=1)
+    mock_redis.ping = AsyncMock(return_value=True)
+
+    # Pipeline
+    mock_pipeline = MagicMock()
+    mock_pipeline.execute = AsyncMock(return_value=[])
+    mock_redis.pipeline.return_value = mock_pipeline
+
+    # PubSub
+    mock_pubsub = MagicMock()
+    mock_pubsub.subscribe = AsyncMock()
+    mock_pubsub.listen = AsyncMock()
+    mock_redis.pubsub.return_value = mock_pubsub
+
+    # 2. Patching dependencies
+    with patch("resync.api.monitoring_dashboard.get_redis_client", return_value=mock_redis), \
+         patch("resync.api.monitoring_dashboard.decode_token") as mock_decode, \
+         patch("resync.core.metrics.runtime_metrics") as mock_metrics:
+
+        # Setup mocks
+        mock_decode.return_value = {"sub": "admin", "roles": ["admin"]}
+        mock_metrics.get_snapshot.return_value = {
+            "agent": {"initializations": 100, "active_count": 5, "creation_failures": 2},
+            "slo": {"api_error_rate": 0.02, "availability": 0.99, "tws_connection_success_rate": 1.0}
+        }
+
+        store = DashboardMetricsStore()
+        sample = MetricSample(timestamp=time.time(), datetime_str="12:00:00", requests_total=100)
+
+        # TESTE A: Persistência no Redis
+        await store.add_sample(sample)
+        mock_pipeline.lpush.assert_called_once_with(ANY, ANY)
+        lpush_args, _ = mock_pipeline.lpush.call_args
+        assert lpush_args[0]
+        assert '"requests_total":100' in lpush_args[1]
+        mock_pipeline.execute.assert_called_once()
+
+        # TESTE B: Broadcast via Pub/Sub
+        await collect_metrics_sample()
+        mock_redis.publish.assert_called_once_with(REDIS_CH_BROADCAST, ANY)
+
+        # TESTE C: WebSocket Relay
+        mock_ws = AsyncMock()
+        mock_ws.send_text = AsyncMock()
+        await ws_manager.connect(mock_ws)
+        await ws_manager.broadcast('{"status": "sync_test"}')
+        mock_ws.send_text.assert_called_once_with('{"status": "sync_test"}')
+        await ws_manager.disconnect(mock_ws)
+
+if __name__ == "__main__":
+    asyncio.run(verify_dashboard_redis())
diff --git a/workflows/nodes_verbose.py b/workflows/nodes_verbose.py
index 24169c9..585b991 100644
--- a/workflows/nodes_verbose.py
+++ b/workflows/nodes_verbose.py
@@ -12,6 +12,9 @@

 logger = structlog.get_logger(__name__)

+_JOB_EXECUTION_HISTORY_LIMIT = 2000
+_METRICS_HISTORY_LIMIT = 5000
+

 async def fetch_job_history(
     db: Any,
@@ -100,20 +103,20 @@ async def fetch_job_history(
                     query,
                     {"job_name": job_name, "cutoff_date": cutoff_date}
                 )
-                rows = result.fetchall()
+                rows = result.mappings().fetchall()

                 if rows:
                     job_history = [
                         {
-                            "timestamp": row[0].isoformat() if row[0] else None,
-                            "job_name": row[1],
-                            "workstation": row[2] or "UNKNOWN",
-                            "status": row[3] or "UNKNOWN",
-                            "return_code": row[4] or 0,
-                            "runtime_seconds": row[5] or 0,
-                            "scheduled_time": row[6].isoformat() if row[6] else None,
-                            "actual_start_time": row[7].isoformat() if row[7] else None,
-                            "completed_time": row[8].isoformat() if row[8] else None,
+                            "timestamp": row["timestamp"].isoformat() if row["timestamp"] else None,
+                            "job_name": row["job_name"],
+                            "workstation": row["workstation"] or "UNKNOWN",
+                            "status": row["status"] or "UNKNOWN",
+                            "return_code": row["return_code"] or 0,
+                            "runtime_seconds": row["runtime_seconds"] or 0,
+                            "scheduled_time": row["scheduled_time"].isoformat() if row["scheduled_time"] else None,
+                            "actual_start_time": row["actual_start_time"].isoformat() if row["actual_start_time"] else None,
+                            "completed_time": row["completed_time"].isoformat() if row["completed_time"] else None,
                         }
                         for row in rows
                     ]
@@ -302,18 +305,18 @@ async def fetch_workstation_metrics(
                     query,
                     {"workstation": workstation, "cutoff_date": cutoff_date}
                 )
-                rows = result.fetchall()
+                rows = result.mappings().fetchall()

                 if rows:
                     metrics = [
                         {
-                            "timestamp": row[0].isoformat() if row[0] else None,
-                            "workstation": row[1],
-                            "cpu_percent": float(row[2]) if row[2] is not None else 0.0,
-                            "memory_percent": float(row[3]) if row[3] is not None else 0.0,
-                            "disk_percent": float(row[4]) if row[4] is not None else 0.0,
-                            "network_mbps": float(row[5]) if row[5] is not None else 0.0,
-                            "active_jobs": int(row[6]) if row[6] is not None else 0,
+                            "timestamp": row["timestamp"].isoformat() if row["timestamp"] else None,
+                            "workstation": row["workstation"],
+                            "cpu_percent": float(row["cpu_percent"]) if row["cpu_percent"] is not None else 0.0,
+                            "memory_percent": float(row["memory_percent"]) if row["memory_percent"] is not None else 0.0,
+                            "disk_percent": float(row["disk_percent"]) if row["disk_percent"] is not None else 0.0,
+                            "network_mbps": float(row["network_mbps"]) if row["network_mbps"] is not None else 0.0,
+                            "active_jobs": int(row["active_jobs"]) if row["active_jobs"] is not None else 0,
                         }
                         for row in rows
                     ]
@@ -1792,22 +1795,22 @@ async def fetch_job_execution_history(
             query_str += " AND workstation = :workstation"
             params["workstation"] = workstation

-        query_str += " ORDER BY timestamp DESC LIMIT 2000"
+        query_str += f" ORDER BY timestamp DESC LIMIT {_JOB_EXECUTION_HISTORY_LIMIT}"

         result = await db.execute(text(query_str), params)
-        rows = result.fetchall()
+        rows = result.mappings().fetchall()

         job_history = [
             {
-                "timestamp": row[0].isoformat() if row[0] else None,
-                "job_name": row[1],
-                "workstation": row[2] or "UNKNOWN",
-                "status": row[3] or "UNKNOWN",
-                "return_code": row[4] or 0,
-                "runtime_seconds": row[5] or 0,
-                "scheduled_time": row[6].isoformat() if row[6] else None,
-                "actual_start_time": row[7].isoformat() if row[7] else None,
-                "completed_time": row[8].isoformat() if row[8] else None,
+                "timestamp": row["timestamp"].isoformat() if row["timestamp"] else None,
+                "job_name": row["job_name"],
+                "workstation": row["workstation"] or "UNKNOWN",
+                "status": row["status"] or "UNKNOWN",
+                "return_code": row["return_code"] or 0,
+                "runtime_seconds": row["runtime_seconds"] or 0,
+                "scheduled_time": row["scheduled_time"].isoformat() if row["scheduled_time"] else None,
+                "actual_start_time": row["actual_start_time"].isoformat() if row["actual_start_time"] else None,
+                "completed_time": row["completed_time"].isoformat() if row["completed_time"] else None,
             }
             for row in rows
         ]
@@ -1871,22 +1874,22 @@ async def fetch_workstation_metrics_history(
             query_str += " AND workstation = :workstation"
             params["workstation"] = workstation

-        query_str += " ORDER BY timestamp DESC LIMIT 5000"
+        query_str += f" ORDER BY timestamp DESC LIMIT {_METRICS_HISTORY_LIMIT}"

         result = await db.execute(text(query_str), params)
-        rows = result.fetchall()
+        rows = result.mappings().fetchall()

         metrics_history = [
             {
-                "timestamp": row[0].isoformat() if row[0] else None,
-                "workstation": row[1],
-                "cpu_percent": row[2],
-                "memory_percent": row[3],
-                "disk_percent": row[4],
-                "load_avg_1min": row[5],
-                "cpu_count": row[6],
-                "total_memory_gb": row[7],
-                "total_disk_gb": row[8],
+                "timestamp": row["timestamp"].isoformat() if row["timestamp"] else None,
+                "workstation": row["workstation"],
+                "cpu_percent": float(row["cpu_percent"]) if row["cpu_percent"] is not None else 0.0,
+                "memory_percent": float(row["memory_percent"]) if row["memory_percent"] is not None else 0.0,
+                "disk_percent": float(row["disk_percent"]) if row["disk_percent"] is not None else 0.0,
+                "load_avg_1min": float(row["load_avg_1min"]) if row["load_avg_1min"] is not None else 0.0,
+                "cpu_count": int(row["cpu_count"]) if row["cpu_count"] is not None else 0,
+                "total_memory_gb": float(row["total_memory_gb"]) if row["total_memory_gb"] is not None else 0.0,
+                "total_disk_gb": float(row["total_disk_gb"]) if row["total_disk_gb"] is not None else 0.0,
             }
             for row in rows
         ]
